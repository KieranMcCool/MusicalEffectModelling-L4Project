## 29/09/2017 - 3 Hours

* Began reading the first chapter of colah.github.io
* Watched YouTube Lectures on machine learning and neural networks

## 03/10/2017 - 2 Hours

* Read some of Section 1 of Nielson's book on machine learning

## 04/10/2017 - 2 Hours

* Prepared presentation on project for Advanced Geographies Presentation
* Installed PyTorch successfully
* Had trouble with Keras installation.

## 05/10/2017 - 2 Hours 

* Second project meeting
* Began reading "The Unreasonable Effectiveness of Recurrent Neural Networks."
* Spent time looking for tutorials on using PyTorch.

## 11/10/2017 - 2 Hours

* Moved Keras and PyTorch installations from using system Python and Pip to Anaconda virtual environment.
* Reread "The Unreasonable Effectiveness of Recurrent Neural Networks"
* Read Chris Olah's blog post on LSTM Netorks

## 12/10/2017 - 1 Hour

* Third project meeting
* Digitised minutes from today's meeting.

## 13/10/2017 - 2 Hours

* Started working on pipeline for generating test data
    - SciPy for generating wav files, Mrs Watson for processing them through the VST plugin.
    - Having trouble getting Mrs Watson to read the wav files generated.

## 17/10/2017 - 3 Hours

* Test data pipeline is mostly in place, just working out some bugs with MrsWatson.
	- MrsWatson processes the files and data looks to be there but no software can seem to read the resulting files...
	- Might try with MacOS/Windows instead of Linux as these appear to be better supported.
	- Choice of plugins also limited by poor support on Linux from VST developers.
    - Frustratingly, everything worked with only minor changes on Windows.
* Upon hearing the output from the VST plugins, I decided to move away from random frequency sweeps to those found within a guitars frequency range.
    - Researched what this range was and wrote code to replicate it.
* Looking at setting variables on effect with MrsWatson.

## 18/10/2017 - 1 Hour

* Worked through introduction PyTorch tutorials on their website.

## 19/10/2017 - 1 Hour

* Wrote up minutes from Meeting 4
    - Also fixed dates of meeting minutes, I had been forgetting to change them.

## 23/10/2017 - 1 Hours

* Cleaned up code for test data pipeline, almost ready to be finalised into a python CLI program.
* Read additional documentation for PyTorch

## 24/10/2017 - 2 Hours

* Followed PyTorch examples until intermediate
* Read some blogs about PyTorch
    - [](https://www.oreilly.com/ideas/why-ai-and-machine-learning-researchers-are-beginning-to-embrace-pytorch)

## 25/10/2017 - 2 Hours

* Adapting basic neural network from tutorials into something which can accept the wav data as read by SciPy
    - Reading in wav files with SciPy as Numpy arrays, converting to PyTorch tensors.

## 27/10/2017 - 1 Hour

* Wrote up minutes from meeting yesterday

## 30/10/2017 - 2 Hours

* Discovered bug in the pipeline involving MrsWatson
    - Picky about files/plugins and I'm not even sure it's working at all.
    - Tried a few different plugins, some work better than others, some crash all together
    - Inconsistency running even with the same command multiple times
* Tried RenderMan, an alternative to MrsWatson
    - Lots of dependencies
    - Couldn't work out how to compile it as some dependencies have updated their code and are no longer compatible but don't have legacy builds available for download.

## 31/10/2017 - 2 Hours

* Frustrated with Pipeline issues, decided to do what I could for now.
* Adapting examples for sound
    - Started writing code for sliding window approach.
    - Taking a wav file and splitting it into equal sized blocks, padding if necessary
    - This makes it easier to train the network
* Looked some more at DeepSound, might be useful to borrow some of their RNN code at a later date.

## 7/11/2017 - 5 Hours

* Minutes written up from last meeting (technically done on the day of the meeting, just digitised them)
* Code for generating training data is totally redone
    - Data is **far** more random than it was before.
    - Command line parameters added to allow easy test data generation
    - Randomisation made much simpler
    - Much more flexible options for creating test data, makes it easier to add even more variability should the need arise.
* Reaper command line instead of MrsWatson as issues from last time could not be fixed.

## 8/11/2017 - 4 Hours

* Created a bash script to create test data (generated by python script then automatically processed by reaper) with command line arguments to allow me to change duration and quantity of files.
* Finally got the network working and iterating over all the files
    - **REALLY EXCITING, LOSS IS ALREADY DECREASING SUBSTANTIALLY!!!**
    - Starts in the high millions and finishes in the low 100k, gets as low as 25k-30k on some files
    - Loss does increase when a new file is loaded but then quickly starts to decrease the more time it spends with the file. This might indicate overfitting a little bit? 
    - Some samples have absurdly high loss compared to others, but this seems to get less exagerated the more iterations the network is run for.
* Tried to make data even more random beyond the improvements made last night, this is still a work in progress.

##Â 10/11/2017 - 1 Hour

* Wrote up minutes from last meeting

## 14/11/2017 - 4 Hours

* Moved commonly used variables into globals.py
    - Things like sample rate etc
* Finished sliding window approach
    - Spacial awareness adjustable within globals.py
* Data represented as objects instead of list of lists
    - Easier memory management
    - Much easier to reason about the code.
    - Can be run on arbitrary files from path.
* Realistic network variables
    - Input magnitude = 64, Output Magnitude = 1
* Ran some initial experiments on reverb
    - 64 sample size didn't produce very good results
    - Increased to 200 for greater spacial awareness, which definitely improved things but training was painfully slow.

## 15/11/2017 - 1 Hours

* Set up a TS808 effects chain to train on
* Ran an initial experiment on TS808


## 16/11/2017 - 1 Hour

* Had project meeting
* Wrote up project meeting notes
* Looked at Conv1D in PyTorch
    - Can't seem to get it working with my data, wants 3D tensor, audio data is 1D

## 20/11/2017 - 1 Hour

* Looked at DeepSound and ProjectMagenta for potential example of conv1d applied to audio data.
    - Still not quite sure, DeepSound uses RNN instead and ProjectMagenta uses TensorFlow

## 22/11/2017 - 2 Hours

* Model saves at each checkpoint, not yet able to load a checkpoint.
* Verified that the training process is actually working by training the model to simply reproduce the input, this works as loss hits 0 very quickly.
* Ran current network on linear distortion
    - Overfitting seems to be a problem

## 23/11/2017 - 1 Hour

* Project meeting and wrote up minutes

## 27/11/2017 - 2 Hours

* Started working on getting convolutions added
    - Still struggling to understand what's going on
    - Getting errors saying expected 3D tensor when data.dim() reports we are using a 3D tensor?!?!?1

## 29/11/2017 - 3 Hours

* Frustrated, tried a change of tactics.
    - Instead of going for a 200x64x1 Tensor, let's just go for 1x1x64
    - Only focus on the 64 time slice
    - Seems to be working pretty well, loss is going lower than I've seen it before
* Network now going Conv1D(64) -> ReLU -> Conv1D(32) -> ReLU -> Conv1D(1) -> ReLU 
    - More convincing results than ever.

## 30/11/2017 - 1 Hour

* Wrote up minutes from meeting

## 5/11/2017 - 4 Hours

* Got batches of 200 working
    - Hoping to be able to randomly choose samples to train in a given batch
    - Also hoping to be able to run sequentially so I can run on output files 200 times faster.
* Some code cleanup
    - Model's forward function cleaned up by encapsulating multiple layers in Sequentials.
* Started moving run-time code into main.py so that net.py just contains the model and functions directly related to it.
    - Will be easier to reason about code base when every component is in its distinct location
    - Means I can look into adding command line arguments without ending up with a huge number of lines detracting from the pytorch specific code.
